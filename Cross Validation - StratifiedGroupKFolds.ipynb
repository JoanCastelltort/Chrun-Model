{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las bibliotecas necesarias y el dataset previamente limpiado\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from itertools import combinations\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gym = pd.read_excel('DatosParaModelo.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Logistic_Regression (DataFrame, Splits):\n",
    "\n",
    "    lista_AUC_kfolds = []\n",
    "\n",
    "    Modelo_reg_log = LogisticRegression(penalty=None, max_iter=3000)\n",
    "\n",
    "    # Se configuran las variables de entrada y salida, la lista de identificadores de clientes y se prepara las divisiones del dataset con estratificación\n",
    "    X = DataFrame.drop(columns = ['IdPersona', 'Baja', 'Mes'])\n",
    "    y = DataFrame['Baja']\n",
    "    Id_Clientes = DataFrame['IdPersona']\n",
    "    kfold = StratifiedKFold(n_splits=Splits, shuffle=True, random_state=1)\n",
    "\n",
    "    # Bucle para iterar sobre los diferentes folds separando entre train y test con divisiones estratificadas según Ids de clientes\n",
    "    for Train_data, Test_data in kfold.split(X, y, groups = Id_Clientes):\n",
    "        X_train, X_test = X.iloc[Train_data], X.iloc[Test_data]\n",
    "        y_train, y_test = y.iloc[Train_data], y.iloc[Test_data]\n",
    "\n",
    "        # Entrenamiento del modelo y cálculo del AUC_PR sobre el conjunto de test\n",
    "        Modelo_reg_log.fit(X_train, y_train)\n",
    "        Predicciones_reg = Modelo_reg_log.predict_proba(X_test)\n",
    "        AUC_ROC = roc_auc_score(y_test, Predicciones_reg[:, 1])\n",
    "        lista_AUC_kfolds.append(AUC_ROC)\n",
    "\n",
    "    # Resultado\n",
    "    Mean_AUC = np.mean(lista_AUC_kfolds)\n",
    "    return print(f'El AUC del Modelo de Regresión Logística es: {Mean_AUC}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_Forest(Profundidades, Estimadores, DataFrame, Splits):\n",
    "\n",
    "  lista_parametros = []\n",
    "  lista_AUC = []\n",
    "\n",
    "  for Depth in Profundidades:\n",
    "    for n_estimators in Estimadores:\n",
    "      lista_AUC_kfolds = []\n",
    "      \n",
    "      # Se configuran las variables de entrada y salida, la lista de identificadores de clientes y se prepara las divisiones del dataset con estratificación\n",
    "      X = DataFrame.drop(columns = ['IdPersona', 'Baja', 'Mes'])\n",
    "      y = DataFrame['Baja']\n",
    "      Id_Clientes = DataFrame['IdPersona']\n",
    "      kfold = StratifiedKFold(n_splits=Splits, shuffle=True, random_state=1)\n",
    "\n",
    "      # Bucle para iterar sobre los diferentes folds separando entre train y test con divisiones estratificadas según Ids de clientes   \n",
    "      for Train_data, Test_data in kfold.split(X, y, Id_Clientes):\n",
    "        X_train, X_test = X.iloc[Train_data], X.iloc[Test_data]\n",
    "        y_train, y_test = y.iloc[Train_data], y.iloc[Test_data]    \n",
    "    \n",
    "        # Entrenamiento del modelo y cálculo del AUC_PR sobre el conjunto de test\n",
    "        Modelo_random_forest = RandomForestClassifier(max_depth=Depth, n_estimators=n_estimators, random_state=1).fit(X_train, y_train)\n",
    "        Predicciones_rndm_frst = Modelo_random_forest.predict_proba(X_test)\n",
    "        AUC_ROC = roc_auc_score(y_test, Predicciones_rndm_frst[:, 1])\n",
    "        lista_AUC_kfolds.append(AUC_ROC)\n",
    "\n",
    "      # Promediado de los resultados de los diferentes folds y agregado de resultado en las listas\n",
    "      Mean_AUC = np.mean(lista_AUC_kfolds)\n",
    "      lista_AUC.append(Mean_AUC)    \n",
    "      lista_parametros.append([Depth, n_estimators])\n",
    "\n",
    "  # Resultados\n",
    "  AUC_max_value = np.argmax(lista_AUC)\n",
    "  return print(f'El AUC del modelo Random Forest es {lista_AUC[AUC_max_value]}, para un nivel de profundidad de {lista_parametros[AUC_max_value][0]} y consta de {lista_parametros[AUC_max_value][1]} árboles de decisión')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gradient_Boosting (Profundidades, Estimadores, DataFrame, Splits):\n",
    "\n",
    "    lista_parametros = []\n",
    "    lista_AUC = []\n",
    "\n",
    "    for Depth in Profundidades:\n",
    "        for n_estimators in Estimadores:\n",
    "            lista_AUC_kfolds = []\n",
    "\n",
    "            # Se configuran las variables de entrada y salida, la lista de identificadores de clientes y se prepara las divisiones del dataset con estratificación\n",
    "            X = DataFrame.drop(columns = ['IdPersona', 'Baja', 'Mes'])\n",
    "            y = DataFrame['Baja']\n",
    "            Id_Clientes = DataFrame['IdPersona']\n",
    "            kfold = StratifiedKFold(n_splits=Splits, shuffle=True, random_state=1)\n",
    "            \n",
    "            # Bucle para iterar sobre los diferentes folds separando entre train y test con divisiones estratificadas según Ids de clientes\n",
    "            for Train_data, Test_data in kfold.split(X, y, groups = Id_Clientes):\n",
    "                X_train, X_test = X.iloc[Train_data], X.iloc[Test_data]\n",
    "                y_train, y_test = y.iloc[Train_data], y.iloc[Test_data]\n",
    "\n",
    "                # Entrenamiento del modelo y cálculo del AUC_PR sobre el conjunto de test\n",
    "                Modelo_xgboost = xgb.XGBClassifier(n_estimators=n_estimators, max_depth=Depth, objective='binary:logistic').fit(X_train, y_train)\n",
    "                Predicciones_xgb = Modelo_xgboost.predict_proba(X_test)\n",
    "                AUC_ROC = roc_auc_score(y_test, Predicciones_xgb[:, 1])\n",
    "                lista_AUC_kfolds.append(AUC_ROC)\n",
    "\n",
    "            # Promediado de los resultados de los diferentes folds y agregado de resultado en las listas\n",
    "            Mean_AUC = np.mean(lista_AUC_kfolds)\n",
    "            lista_AUC.append(Mean_AUC)\n",
    "            lista_parametros.append([Depth, n_estimators])\n",
    "\n",
    "    # Resultados\n",
    "    AUC_max_value = np.argmax(lista_AUC)\n",
    "    return print(f'El AUC del modelo XGBoost es {lista_AUC[AUC_max_value]}, para un nivel de profundidad de {lista_parametros[AUC_max_value][0]} y consta de {lista_parametros[AUC_max_value][1]} árboles de decisión')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables de los Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Splits = 50\n",
    "Profundidades_xgb = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "Estimadores_xgb = [20, 40, 60, 80, 100, 120, 140, 160, 180, 200]\n",
    "Profundidades_forest = [10, 11, 12, 13, 14, 15]\n",
    "Estimadores_forest = [150, 200, 250, 300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejecución de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El AUC del Modelo de Regresión Logística es: 0.8354133811049952\n"
     ]
    }
   ],
   "source": [
    "Logistic_Regression(data_gym, Splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El AUC del modelo XGBoost es 0.8629916358924864, para un nivel de profundidad de 5 y consta de 40 árboles de decisión\n"
     ]
    }
   ],
   "source": [
    "Gradient_Boosting(Profundidades_xgb, Estimadores_xgb, data_gym, Splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El AUC del modelo Random Forest es 0.8665523290159848, para un nivel de profundidad de 14 y consta de 300 árboles de decisión\n"
     ]
    }
   ],
   "source": [
    "Random_Forest(Profundidades_forest, Estimadores_forest, data_gym, Splits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EAE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
